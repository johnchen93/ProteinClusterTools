{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run the package to build sequence similarity networks and clusterings of a protein family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that is required is a fasta file of protein sequences.  \n",
    "\n",
    "The entire pipeline is run from the command line using python. After the cluster definitions are generated, the package also provides various helper functions to visualize and annotate the data.      \n",
    "  \n",
    "**Note:**\n",
    "Sequence headers in the fasta will be trimmed at the first space and converted to numeric IDs for the process.  \n",
    "This is the easiest way to ensure any arbitrarily named set of sequences can be processed without issue. Later notebooks will show how to map the IDs back given a particular downstream process.\n",
    "\n",
    "**Another note:**\n",
    "Examples in this notebook attempt to use the bash shell to execute examples. But assuming you have it installed, you can also run the same commands directly from command line (assuming the correct python environment is activated). All cells start with '%%bash', which is just for this notebook, and does not need to be copied if running the commands anywhere else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pipeline options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the 'proteinclustertools' has been installed, the main processing pipeline can be accessed with the following command.  \n",
    "  \n",
    "Keep in mind that for the package to be found you need to be using the environment (conda, venv, Jupyter kernel, whichever is relevant for where the code is being run) that has all the requirements installed.\n",
    "\n",
    "The following is an example of the options available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: pipeline.py [-h] [-d D] [-p P] [-fa FA] [-A] [-MC] [-P]\n",
      "                   [-cc CC [CC ...]] [-cluster_lines CLUSTER_LINES] [-f F]\n",
      "                   [-RMC] [-cluster_jobs CLUSTER_JOBS] [-E] [-CE] [-t T]\n",
      "                   [-KF KF] [-KM] [-K K [K ...]] [-FKM] [-max_k MAX_K] [-HC]\n",
      "                   [-CT] [-FHC] [-U]\n",
      "\n",
      "Pipeline for analyzing protein families using unsupervised clustering. Uses\n",
      "either homology or vector embeddings to cluster sequences.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "General arguments:\n",
      "  -d D, -directory D    Output directory for files (default: out/)\n",
      "  -p P, -prefix P       Prefix for output files (default: ssn)\n",
      "  -fa FA, -fasta FA     Fasta file to analyze. Only needs to be given once.\n",
      "                        (default: None)\n",
      "\n",
      "Homology based method:\n",
      "  -A, -all_by_all       Run mmseqs all-by-all search (default: False)\n",
      "  -MC, -mmseqs_cluster  Cluster mmseqs results (default: False)\n",
      "  -P, -cluster_percentiles\n",
      "                        Use percentiles of mmseqs results to do clustering.\n",
      "                        (default: False)\n",
      "  -cc CC [CC ...], -cluster_cutoffs CC [CC ...]\n",
      "                        Manually set cutoffs for clustering. Is ignored if -P\n",
      "                        is set. (default: None)\n",
      "  -cluster_lines CLUSTER_LINES\n",
      "                        Number of lines to read at once, adjust for memory\n",
      "                        consumption. (default: 10000000)\n",
      "  -f F, -filter F       List of IDs to filter for. Can be used for mmseqs\n",
      "                        clustering, kmeans, and UMAP. (default: None)\n",
      "  -RMC, -redo_mmseqs_clustering\n",
      "                        Redo steps for mmseqs clustering. (default: False)\n",
      "  -cluster_jobs CLUSTER_JOBS\n",
      "                        Number of jobs to use for clustering (default: None)\n",
      "\n",
      "Vector embedding:\n",
      "  -E, -embed_vectors    Embed vectors (default: False)\n",
      "  -CE, -continue_embed  Continue embedding vectors, in case of interrupted\n",
      "                        run. (default: False)\n",
      "  -t T, -tok_per_batch T\n",
      "                        Number of tokens per batch for embedding. Reduce if\n",
      "                        running out of memory. (default: 30000)\n",
      "\n",
      "Vector based methods:\n",
      "  -KF KF, -keep_features KF\n",
      "                        Number of features to use in vector based methods.\n",
      "                        (default: 30)\n",
      "  -KM, -kmeans          Run kmeans clustering (default: False)\n",
      "  -K K [K ...], -kmeans_clusters K [K ...]\n",
      "                        Number of kmeans clusters. Also used for setting\n",
      "                        cluster count when flattening hierachical clusters.\n",
      "                        (default: [])\n",
      "  -FKM, -flatten_kmeans\n",
      "                        Subsect kmeans clusters based on max_k tree (default:\n",
      "                        False)\n",
      "  -max_k MAX_K          Max K to further subdivide into clusters (default:\n",
      "                        None)\n",
      "  -HC, -hierarchical_clustering\n",
      "                        Run hierarchical clustering (default: False)\n",
      "  -CT, -convert_hierarchical_tree\n",
      "                        Convert hierarchical tree to newick format (default:\n",
      "                        False)\n",
      "  -FHC, -flatten_hierarchical_clustering\n",
      "                        Flatten hierarchical clustering (default: False)\n",
      "  -U, -umap             Run UMAP (default: False)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline always starts with cleaning an input fasta file. This can be run as a separate first step, or it will be handled automatically when running any analysis options while providing the '-fa' argument.\n",
    "\n",
    "**Note:** A large part of the pipeline is just keeping track of consecutive input/outputs between steps, and so the fasta file cannot be changed once inputed as it assumes subsequent steps make use of this file.  \n",
    "There are two options to work changes in the data:  \n",
    "1. If the desired data is a subset of the original, the '-f' or '-filter' option can be used for the clustering methods to isolate just the subset of interest.\n",
    "2. (Easiest in most cases) Just start the analysis in a new folder, for most datasets (~50-100k sequences) the run time to redo is not that long.\n",
    "\n",
    "**Note:** All commands require the '-d' ('-directory', where to put output) and '-p' ('-prefix', how to label files) arguments. The folder containing the analysis can be moved and renamed, as the file tracking is completely internal to that directory. However, this also means all analyses have to reuse that same directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following will produce a cleaned fasta file, and the conversion header map for future reference.\n",
    "\n",
    "Note that in this case we use the 100% representatives of the IPR001761 family of proteins. Clustering can be easily generated using CD-hit or mmseqs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned fasta is in: ../output/IPR001761_cleaned.fasta\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -d ../output -p IPR001761 -fa ../data/IPR001761_rep100.fasta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequent commands no longer need the '-fa' option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 main work flows grouped into 2 methods:\n",
    "\n",
    "Homology method - Build a sequence similarity network using MMSeqs pairwise sequence alignments, and cluster the network by detecting connected components above a given cut-off.\n",
    "\n",
    "Representation method - Convert sequences into vectors using the ESM1b protein language model, then conduct either 1) Kmeans clustering or 2) hierarchical clustering (RAM intensive, exponentially scales with sequence count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Homology method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All-by-all pairwise alignments can be run easily using the '-A' option.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -d ../output -p IPR001761 -A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a 'mmseqs_search.tsv' file with all the pairwise alignment bitscores.  \n",
    "  \n",
    "Alternatively, one can load their own table of pairwise metrics for clustering and skip the *-A* option. In the following steps, add the *-edge_table* command with a path to the table. The custom table needs to be tab-separated, 3 columns, with target/query in the 1st 2 columns, and score in the 3rd; headers need to be present, but their value do not matter. Tables with more columns than needed are okay, but only the first 3 columns will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "To identify clusters, use the '-MC' option. It is necessary to identify the cut-offs where clusters should be detected. After the all-by-all alignments, the pipeline automatically sets bitscore cutoffs at the 10,25,50,75, and 90 percentiles of the full distribution (sampled up to 1M pairwise bitscores).\n",
    "\n",
    "So one can use the percentiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -d ../output -p IPR001761 -MC -P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or specify a list of cut-offs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -d ../output -p IPR001761 -MC -cc 100 150 200 250 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example using custom table (feeding existing table as an example). Need to use the '-redo_mmseqs_clustering' option to force redoing cutoffs that were already done.\n",
    "\n",
    "Note: custom tables do not support the percentiles option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -d ../output -p IPR001761 -edge_table ../output/IPR001761_mmseqs_search.tsv -MC -cc 100 150 -redo_mmseqs_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering tries to use multiprocessing, and may consume too much RAM on very large MMSeqs results files. If this is the case, the user can try reducing the number of lines being read by each job, or limit the maximum number of jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -d ../output -p IPR001761 -MC -P -cluster_lines 1000000 -cluster_jobs 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate clustering files under a 'mmseqs_clustering' folder in the target directory. Which can now be used for downstream steps.  \n",
    "  \n",
    "See the [**hierarchical cluster plot**](./hierarchical_cluster_plot.ipynb) notebook for an example of how to visualize the clusters using the tools in the package.  \n",
    "See the [**representative selection**](./representative_selection.ipynb) notebook for an example of how to select representatives given clustering definitions.\n",
    "  \n",
    "Both examples are applicable regardless of how the clustering was generated (any of the methods)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Vector representation methods\n",
    "  \n",
    "Both representation methods require the vector embeddings to be generated first ('-E' option).\n",
    "\n",
    "**Note:** This was intended to be run on a computer with a dedicated GPU, and requires pytorch and cuda to have been properly installed.  \n",
    "Without a GPU, this code could still work in theory as it may try to run it on CPU instead. In this case, it will likely run much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -d ../output -p IPR001761 -E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the embedding generation can be skipped, and the user can supply their own embeddings.\n",
    "\n",
    "Use the -embeddings_dict option, and specify a path to a pickled dictionary with the sequence IDs as keys and the embeddings vectors as values (1D, already pooled).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Kmeans clustering\n",
    "\n",
    "The implementation used is bisecting K-means, which generates a bisecting cluster tree. This tree can then be subdivided to generate lower values of K so that the hierarchical relationship is preserved. This is necessary as K-means (including bisecting K-means) does not produce consistent hierarchical relationships across different K.   \n",
    "\n",
    "**Note:** With Kmeans, there is stochasticity to the clustering. The pipeline uses a fixed random number seed to get the same results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to produces clusters and trees with Kmeans, use the '-KM' option. Note that the clustering parameter for Kmeans is the number of final clusters, the user may need to experiment to identify the best results.  \n",
    "  \n",
    "Supply the list of cluster counts with '-K'. In this case, we make up to 10,000 clusters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned fasta is in: ../output/IPR001761_cleaned.fasta\n",
      "Loading embeddings for kmeans\n",
      "Loading embeddings for kmeans\n",
      "Reducing feature dimensions with PCA\n",
      "Running kmeans\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -d ../output -p IPR001761 -KM -K 10000 -KF 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the '-KF' option. When using vectors, it is possible to reduce the vector complexity using PCA first. By default, all vector analyses reduce the vectors to 30 dimensions. Set the -KF to 0 to use the full vectors.\n",
    "\n",
    "The clustering definitions are outputed to 'kmeans/max_k/' folder in the target directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take this tree structure and further divide it into lower cluster counts.\n",
    "\n",
    "In this case, we use the same cluster counts as those produced when clustering the homology method using the percentiles option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -d ../output -p IPR001761 -FKM -max_k 10000 -K 166 505 1403 3939 9094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is stored in 'kmeans/flattened_10000/' (separate folder for each max_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d. Hierarchical clustering\n",
    "  \n",
    "With hierarchical clustering, we first generate a linkage matrix, that can then be used to generate clusterings at different levels, or to build a tree structure for visualization. Start with the '-HC' method to create the linkage matrix. Again, '-KF' can be used to control feature complexity. \n",
    "\n",
    "This pipeline generates linkage matrices using 'cosine' as the metric, and 'weighted' method of clustering.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -d ../output -p IPR001761 -HC -KF 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To produce specific clusters, use the '-FHC' option to 'flatten' the clusters. The pipeline uses the simple method of 'max clust' where similar to Kmeans, the user specifies the desired number of final clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -d ../output -p IPR001761 -FHC -K 166 505 1403 3939 9094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting cluster definitions are in 'hierarchical_clustering' folder in the target directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel to the cluster generation, we can also make a tree structure from the linkage matrix. The function produces the full tree with all sequences, which can be further manipulated (example in the [**tree structure**](./tree_structure.ipynb) notebook).  \n",
    "Simply use the '-CT' option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -d ../output -p IPR001761 -CT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree is created directly in the target directory. Look for the Newick (.nwk) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3e. Conducting UMAP\n",
    "  \n",
    "The vectors can be processed by UMAP to map each sequence directly to a 2D coordinate for visualization. It has the strength of being naturally self-organising and preserving some structure from the higher dimensions, but has various pitfalls for interpretation. \n",
    "  \n",
    "**Note:** Visualizations using UMAP can be sensitive to hyperparameters. However, for simplicity, the pipeline uses default options.  \n",
    "The user is encouraged to test UMAP (or another dimensionality reduction technique like TSNE) to see if different settings change their interpretations.  \n",
    "In this case, they'll need to write their own code (usually just 1-2 lines) and can manually provide the embeddings from this pipeline.    \n",
    "\n",
    "The pipeline provides the '-U' option to make conduct UMAP on all sequences that have been converted into vectors. Again, '-KF' can be used to control vector complexity.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m proteinclustertools.pipeline -d ../output -p IPR001761 -U -KF 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting 'umap.csv' is created in the target directory, and is a dataframe with an x and y coordinate for each sequence ID (in numerical format). This can be conveniently plotted using any scatter plot function or graphing software. See the [**UMAP plot**](./UMAP_plot.ipynb) notebook for an example of interactive visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustertools2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
